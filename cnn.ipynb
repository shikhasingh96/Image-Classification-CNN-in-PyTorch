{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Installing Required Libraries\n",
    "Installing the required Python libraries: numpy (numerical computations), pillow (image handling), torch (PyTorch library), and torchvision (tools for handling vision datasets and models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.25.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\indra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install numpy pillow torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",

    "\n",
    "# Overview\n",
    "\"In this project, I implemented an image classification pipeline using Convolutional Neural Networks (CNNs) in PyTorch. The goal was to classify images into predefined categories, leveraging the power of deep learning to work with unstructured image data.\"\n",
    "\n",
    "# Key Highlights\n",
    "Deep Learning Expertise:\n",
    "\n",
    "I designed and trained a CNN from scratch, incorporating multiple convolutional layers, max-pooling, and fully connected layers.\n",
    "The model achieved strong performance metrics such as accuracy on the test dataset.\n",
    "Data Preprocessing:\n",
    "\n",
    "I used PyTorch’s torchvision.transforms for image augmentation (e.g., resizing, normalization) to improve generalization and robustness.\n",
    "Model Training:\n",
    "\n",
    "I optimized the model using techniques like stochastic gradient descent (SGD) with learning rate scheduling and momentum.\n",
    "I monitored the training process using training loss and validation accuracy to prevent overfitting.\n",
    "Transfer Learning (Optional if Implemented):\n",
    "\n",
    "I utilized pre-trained models (like ResNet or VGG) for transfer learning to accelerate training and achieve higher accuracy.\n",
    "Model Evaluation:\n",
    "\n",
    "I evaluated the model's performance using accuracy, confusion matrices, and other metrics.\n",
    "Additionally, I implemented visualization techniques like Grad-CAM to interpret which regions of an image influenced the model’s predictions, providing explainability.\n",
    "Deployment:\n",
    "\n",
    "The trained model was saved using torch.save() and tested on new images for real-world applicability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries\n",
    "Imports the libraries necessary for neural network creation, data preprocessing, optimization, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing\n",
    "Converts images to tensors and normalizes them to have a mean of 0.5 and a standard deviation of 0.5 for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading the CIFAR-10 Dataset\n",
    "- Downloads and loads the CIFAR-10 dataset, applying the defined preprocessing.\n",
    "- Creates data loaders for batch processing during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exploring the Dataset and Defining Class Names\n",
    "- Retrieves the first image and its label from the training dataset to inspect its dimensions.\n",
    "- Maps the numeric labels in the CIFAR-10 dataset to human-readable class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Creating the CNN Model and Setting up Loss Function and Optimizer\n",
    "- Defines a CNN with two convolutional layers followed by pooling and fully connected layers for classification\n",
    "- Initializes the CNN, sets the loss function (cross-entropy for multi-class classification), and defines the SGD optimizer with learning rate and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)  # (12, 28, 28)\n",
    "        self.pool = nn.MaxPool2d(2, 2)   # (12, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)  # (24, 10, 10) -> (24, 5, 5) -> Flatten (24 * 5 * 5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training the Model and Model Saving \n",
    "- Trains the CNN for 30 epochs by updating model weights to minimize the loss\n",
    "- Saves the trained model and reloads it for evaluation or further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss: 2.1893\n",
      "Training epoch 1...\n",
      "Loss: 1.7323\n",
      "Training epoch 2...\n",
      "Loss: 1.5243\n",
      "Training epoch 3...\n",
      "Loss: 1.3960\n",
      "Training epoch 4...\n",
      "Loss: 1.3016\n",
      "Training epoch 5...\n",
      "Loss: 1.2198\n",
      "Training epoch 6...\n",
      "Loss: 1.1493\n",
      "Training epoch 7...\n",
      "Loss: 1.0877\n",
      "Training epoch 8...\n",
      "Loss: 1.0347\n",
      "Training epoch 9...\n",
      "Loss: 0.9924\n",
      "Training epoch 10...\n",
      "Loss: 0.9506\n",
      "Training epoch 11...\n",
      "Loss: 0.9141\n",
      "Training epoch 12...\n",
      "Loss: 0.8781\n",
      "Training epoch 13...\n",
      "Loss: 0.8467\n",
      "Training epoch 14...\n",
      "Loss: 0.8161\n",
      "Training epoch 15...\n",
      "Loss: 0.7863\n",
      "Training epoch 16...\n",
      "Loss: 0.7561\n",
      "Training epoch 17...\n",
      "Loss: 0.7309\n",
      "Training epoch 18...\n",
      "Loss: 0.7045\n",
      "Training epoch 19...\n",
      "Loss: 0.6805\n",
      "Training epoch 20...\n",
      "Loss: 0.6543\n",
      "Training epoch 21...\n",
      "Loss: 0.6327\n",
      "Training epoch 22...\n",
      "Loss: 0.6098\n",
      "Training epoch 23...\n",
      "Loss: 0.5888\n",
      "Training epoch 24...\n",
      "Loss: 0.5655\n",
      "Training epoch 25...\n",
      "Loss: 0.5447\n",
      "Training epoch 26...\n",
      "Loss: 0.5277\n",
      "Training epoch 27...\n",
      "Loss: 0.5057\n",
      "Training epoch 28...\n",
      "Loss: 0.4872\n",
      "Training epoch 29...\n",
      "Loss: 0.4658\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch {epoch}...')\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=600, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluating the Model\n",
    "Evaluates the model's performance on the test dataset and calculates accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.28%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Preprocessing New Images and Making Predictions\n",
    "- Preprocesses new images for prediction using the trained model.\n",
    "- Uses the trained model to predict the class of new images and outputs the corresponding class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = ['example 1.jpg', 'example 2.jpg', 'example 3.jpg']\n",
    "images = [load_image(img) for img in image_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: dog\n",
      "Prediction: cat\n",
      "Prediction: deer\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        output = net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction: {class_names[predicted.item()]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
